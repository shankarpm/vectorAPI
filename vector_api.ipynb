{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e288fe9-eb44-49a0-87ca-32d4fadb47c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting psycopg2-binary\n",
      "  Downloading psycopg2_binary-2.9.10-cp312-cp312-macosx_14_0_arm64.whl.metadata (4.9 kB)\n",
      "Downloading psycopg2_binary-2.9.10-cp312-cp312-macosx_14_0_arm64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: psycopg2-binary\n",
      "Successfully installed psycopg2-binary-2.9.10\n"
     ]
    }
   ],
   "source": [
    "! pip install psycopg2-binary flask_sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "afc03de8-7f73-40d1-a7d8-9819c445ac8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated JWT Token: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VyX2lkIjoxMjMsImV4cCI6MTcyOTM2NjM5OX0.1hyH1uOJgKQr12YI3fQAi0WUsEHUQZ5ceZcvMirH6b4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3w/klx7l1r507sbck3rj37j022h0000gn/T/ipykernel_35567/3870710815.py:9: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  expiration_time = datetime.datetime.utcnow() + datetime.timedelta(hours=1)\n"
     ]
    }
   ],
   "source": [
    "import jwt\n",
    "import datetime\n",
    "\n",
    "# Define a secret key for signing the JWT (Keep this secure)\n",
    "SECRET_KEY = 'vector_api_project'\n",
    "\n",
    "def generate_jwt(user_id):\n",
    "    # Set up token expiration time (e.g., 1 hour from now)\n",
    "    expiration_time = datetime.datetime.utcnow() + datetime.timedelta(hours=1)\n",
    "    \n",
    "    # Create the payload with user data and expiration time\n",
    "    payload = {\n",
    "        'user_id': user_id,\n",
    "        'exp': expiration_time\n",
    "    }\n",
    "    \n",
    "    # Encode the JWT with the secret key\n",
    "    token = jwt.encode(payload, SECRET_KEY, algorithm='HS256')\n",
    "    \n",
    "    return token\n",
    "\n",
    "# Usage example\n",
    "token = generate_jwt(user_id=123)\n",
    "print(f\"Generated JWT Token: {token}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8bc052af-b1fa-4daf-b267-0593059bf9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "from flask_sqlalchemy import SQLAlchemy\n",
    "import json\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Configure PostgreSQL Database\n",
    "app.config['SQLALCHEMY_DATABASE_URI'] = 'postgresql+psycopg2://postgres.hzchwyuybezlqyiwgwki:[vector_api_$#$]@aws-0-us-west-1.pooler.supabase.com:6543/postgres'\n",
    "app.config['SQLALCHEMY_TRACK_MODIFICATIONS'] = False\n",
    "\n",
    "db = SQLAlchemy(app)\n",
    "\n",
    "# Define the models (corresponding to your tables)\n",
    "def check_db_connection():\n",
    "    try:\n",
    "        # Try executing a simple query to check the connection\n",
    "        db.session.execute('SELECT 1')\n",
    "        return jsonify({\"message\": \"Database connection successful!\"}), 200\n",
    "    except Exception as e:\n",
    "        return jsonify({\"error\": \"Database connection failed\", \"details\": str(e)}), 500\n",
    "        \n",
    "class API(db.Model):\n",
    "    __tablename__ = 'apis'\n",
    "    api_id = db.Column(db.Integer, primary_key=True)\n",
    "    api_name = db.Column(db.String(255), nullable=False)\n",
    "    base_url = db.Column(db.Text)\n",
    "    description = db.Column(db.Text)\n",
    "    documentation_link = db.Column(db.Text)\n",
    "\n",
    "class Endpoint(db.Model):\n",
    "    __tablename__ = 'endpoints'\n",
    "    endpoint_id = db.Column(db.Integer, primary_key=True)\n",
    "    api_id = db.Column(db.Integer, db.ForeignKey('apis.api_id'))\n",
    "    endpoint_name = db.Column(db.String(255), nullable=False)\n",
    "    endpoint_url = db.Column(db.Text, nullable=False)\n",
    "    http_method = db.Column(db.String(10), nullable=False)\n",
    "    description = db.Column(db.Text)\n",
    "\n",
    "\n",
    "# Define other models (Authentication, Rate Limiting, Headers, etc.) similar to the above.\n",
    "\n",
    "# Function to insert data into the tables\n",
    "\n",
    "@app.route('/api/save', methods=['POST'])\n",
    "def save_data():\n",
    "    data = request.get_json()  # Parse incoming JSON\n",
    "\n",
    "    try:\n",
    "        # Save to 'apis' table\n",
    "        api_data = data.get('apis', {})\n",
    "        new_api = API(\n",
    "            api_name=api_data['api_name'],\n",
    "            base_url=api_data.get('base_url'),\n",
    "            description=api_data.get('description'),\n",
    "            documentation_link=api_data.get('documentation_link')\n",
    "        )\n",
    "        db.session.add(new_api)\n",
    "        db.session.commit()\n",
    "\n",
    "        # Save to 'endpoints' table (related to 'apis')\n",
    "        endpoint_data = data.get('endpoints', {})\n",
    "        new_endpoint = Endpoint(\n",
    "            api_id=new_api.api_id,  # Use the newly created API's id\n",
    "            endpoint_name=endpoint_data['endpoint_name'],\n",
    "            endpoint_url=endpoint_data['endpoint_url'],\n",
    "            http_method=endpoint_data['http_method'],\n",
    "            description=endpoint_data.get('description')\n",
    "        )\n",
    "        db.session.add(new_endpoint)\n",
    "        db.session.commit()\n",
    "\n",
    "        # Similarly handle other tables (authentication_methods, rate_limiting_settings, etc.)\n",
    "        # For each table, retrieve relevant data, create objects and commit them to the database.\n",
    "\n",
    "        return jsonify({\"message\": \"Data saved successfully!\"}), 201\n",
    "\n",
    "    except Exception as e:\n",
    "        db.session.rollback()  # Rollback in case of any error\n",
    "        return jsonify({\"error\": str(e)}), 400\n",
    "\n",
    "# Run the Flask app\n",
    "# if __name__ == '__main__':\n",
    "#     app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ab1dfc58-684c-407b-8417-af34fe92d32a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3w/klx7l1r507sbck3rj37j022h0000gn/T/ipykernel_35567/3502736415.py:10: MovedIn20Warning: The ``declarative_base()`` function is now available as sqlalchemy.orm.declarative_base(). (deprecated since: 2.0) (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)\n",
      "  Base = declarative_base()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API added successfully!\n",
      "Endpoint added successfully!\n",
      "Authentication method added successfully!\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine, Column, Integer, String, Text\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "\n",
    "# Define the PostgreSQL database connection URL\n",
    "DATABASE_URL = \"postgresql://postgres.hzchwyuybezlqyiwgwki:vector_api_$#$@aws-0-us-west-1.pooler.supabase.com:6543/postgres\"\n",
    "engine = create_engine(DATABASE_URL)\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session() \n",
    "Base = declarative_base()\n",
    "\n",
    "# Define a function to create a connection to PostgreSQL\n",
    "def create_connection():\n",
    "    try:\n",
    "        # Use your provided connection string\n",
    "        connection = psycopg2.connect(\n",
    "            user=\"postgres.hzchwyuybezlqyiwgwki\",\n",
    "            password=\"vector_api_$#$\",\n",
    "            host=\"aws-0-us-west-1.pooler.supabase.com\",\n",
    "            port=\"6543\",\n",
    "            dbname=\"postgres\"\n",
    "        )\n",
    "        \n",
    "        # If connection is successful\n",
    "        print(\"Database connection successful!\")\n",
    "        return connection\n",
    "\n",
    "    except OperationalError as e:\n",
    "        # If there's an error connecting to the database\n",
    "        print(f\"Database connection failed: {e}\")\n",
    "        return None\n",
    "\n",
    "# Define a function to close the connection\n",
    "def close_connection(connection):\n",
    "    if connection:\n",
    "        connection.close()\n",
    "        print(\"Connection closed.\")\n",
    "        \n",
    "# Define the API model (equivalent to the 'apis' table in your DB)\n",
    "class API(Base):\n",
    "    __tablename__ = 'apis'\n",
    "    api_id = Column(Integer, primary_key=True)\n",
    "    api_name = Column(String(255), nullable=False)\n",
    "    base_url = Column(Text)\n",
    "    description = Column(Text)\n",
    "    documentation_link = Column(Text)\n",
    "\n",
    "class Endpoint(Base):\n",
    "    __tablename__ = 'endpoints'\n",
    "    endpoint_id = Column(Integer, primary_key=True)\n",
    "    api_id = Column(Integer, nullable=False)  # Foreign key reference to APIs\n",
    "    endpoint_name = Column(String(255), nullable=False)\n",
    "    endpoint_url = Column(Text, nullable=False)\n",
    "    http_method = Column(String(10), nullable=False)\n",
    "    description = Column(Text)\n",
    "\n",
    "class AuthenticationMethod(Base):\n",
    "    __tablename__ = 'authentication_methods'\n",
    "    auth_id = Column(Integer, primary_key=True)\n",
    "    api_id = Column(Integer, nullable=False)  # Foreign key reference to APIs\n",
    "    auth_method = Column(String(50), nullable=False)\n",
    "    credentials = Column(Text)\n",
    "    token_endpoint = Column(Text)\n",
    "    token_expiry = Column(Integer)\n",
    "    refresh_logic = Column(Text)\n",
    "  \n",
    "# Create a new API record\n",
    "def add_new_api(api_name, base_url, description, documentation_link):\n",
    "    new_api = API(\n",
    "        api_name=api_name,\n",
    "        base_url=base_url,\n",
    "        description=description,\n",
    "        documentation_link=documentation_link\n",
    "    ) \n",
    "    # Add the new API record to the session\n",
    "    session.add(new_api)\n",
    "    \n",
    "    # Commit the transaction\n",
    "    try:\n",
    "        session.commit()\n",
    "        print(\"API added successfully!\")\n",
    "        return new_api.api_id\n",
    "    except Exception as e:\n",
    "        session.rollback()\n",
    "        print(f\"Error: {e}\")\n",
    "    finally:\n",
    "        session.close()\n",
    "\n",
    "\n",
    "def add_new_endpoint(api_id, endpoint_name, endpoint_url, http_method, description):\n",
    "    new_endpoint = Endpoint(\n",
    "        api_id=api_id,\n",
    "        endpoint_name=endpoint_name,\n",
    "        endpoint_url=endpoint_url,\n",
    "        http_method=http_method,\n",
    "        description=description\n",
    "    )\n",
    "    # Add the new endpoint record to the session\n",
    "    session.add(new_endpoint)\n",
    "    \n",
    "    # Commit the transaction\n",
    "    try:\n",
    "        session.commit()\n",
    "        print(\"Endpoint added successfully!\")\n",
    "        return new_endpoint.endpoint_id  # Return the primary key of the newly added record\n",
    "    except Exception as e:\n",
    "        session.rollback()\n",
    "        print(f\"Error: {e}\")\n",
    "    finally:\n",
    "        session.close()\n",
    "\n",
    "def add_new_authentication_method(api_id, auth_method, credentials, token_endpoint, token_expiry, refresh_logic):\n",
    "    new_auth_method = AuthenticationMethod(\n",
    "        api_id=api_id,\n",
    "        auth_method=auth_method,\n",
    "        credentials=credentials,\n",
    "        token_endpoint=token_endpoint,\n",
    "        token_expiry=token_expiry,\n",
    "        refresh_logic=refresh_logic\n",
    "    ) \n",
    "    # Add the new authentication method record to the session\n",
    "    session.add(new_auth_method)\n",
    "    \n",
    "    # Commit the transaction\n",
    "    try:\n",
    "        session.commit()\n",
    "        print(\"Authentication method added successfully!\")\n",
    "        return new_auth_method.auth_id  # Return the primary key of the newly added record\n",
    "    except Exception as e:\n",
    "        session.rollback()\n",
    "        print(f\"Error: {e}\")\n",
    "    finally:\n",
    "        session.close()\n",
    "\n",
    "json_object = json.loads(json_data)\n",
    "api_data = json_object['apis']\n",
    "endpoints_data = json_object['endpoints']\n",
    "auth_methods_data = json_object['authentication_methods']\n",
    "\n",
    "api_id = add_new_api(\n",
    "    api_name=api_data['api_name'],\n",
    "    base_url=api_data.get('base_url'),\n",
    "    description=api_data.get('description'),\n",
    "    documentation_link=api_data.get('documentation_link')\n",
    ")\n",
    "\n",
    "if api_id:  # Ensure API was added successfully\n",
    "        add_new_endpoint(\n",
    "            api_id=api_id,\n",
    "            endpoint_name=endpoints_data['endpoint_name'],\n",
    "            endpoint_url=endpoints_data['endpoint_url'],\n",
    "            http_method=endpoints_data['http_method'],\n",
    "            description=endpoints_data['description']\n",
    "        )\n",
    "\n",
    "# Add Authentication Method\n",
    "        add_new_authentication_method(\n",
    "            api_id=api_id,\n",
    "            auth_method=auth_methods_data['auth_method'],\n",
    "            credentials=auth_methods_data['credentials'],\n",
    "            token_endpoint=auth_methods_data['token_endpoint'],\n",
    "            token_expiry=auth_methods_data['token_expiry'],\n",
    "            refresh_logic=auth_methods_data['refresh_logic']\n",
    "        )\n",
    "# print(f\"pk api id - {api_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fe89913e-85b9-407b-a917-6fa149283479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'api_id': 1,\n",
       " 'endpoint_name': 'Get Sample Data',\n",
       " 'endpoint_url': '/data',\n",
       " 'http_method': 'GET',\n",
       " 'description': 'Fetches sample data from the API.'}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoints_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "58f0f5b2-26c9-4995-859d-7897c79a367f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table created successfully\n",
      "CREATE TABLE  users_table (\n",
      "  id INTEGER NOT NULL,\n",
      "  first_name TEXT NOT NULL,\n",
      "  last_name TEXT NOT NULL,\n",
      "  email TEXT NOT NULL\n",
      ");\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2\n",
    "\n",
    "# Define the connection URL\n",
    "DATABASE_URL = \"postgresql://postgres.hzchwyuybezlqyiwgwki:vector_api_$#$@aws-0-us-west-1.pooler.supabase.com:6543/postgres\"\n",
    "\n",
    "# Create an engine instance\n",
    "engine = create_engine(DATABASE_URL)\n",
    " \n",
    "# Function to generate SQL create table statement from the pandas DataFrame\n",
    "def generate_create_table_from_fieldmapping_df(df):\n",
    "    table_definitions = {}\n",
    "\n",
    "    # Iterate over the DataFrame rows\n",
    "    for index, row in df.iterrows():\n",
    "        table_name = row['database_table']\n",
    "        field_name = row['database_field_name']\n",
    "        field_type = row['data_type_conversion']\n",
    "        nullable = 'NULL' if row['is_nullable'] == 'TRUE' else 'NOT NULL'\n",
    "        \n",
    "        if table_name not in table_definitions:\n",
    "            table_definitions[table_name] = []\n",
    "        \n",
    "        # Append field definition to the table\n",
    "        table_definitions[table_name].append(f\"{field_name} {field_type.upper()} {nullable}\")\n",
    "    \n",
    "    # Generate the SQL CREATE TABLE statements\n",
    "    for table_name, fields in table_definitions.items():\n",
    "        fields_str = \",\\n  \".join(fields)\n",
    "        create_table_sql = f\"CREATE TABLE IF NOT EXISTS {table_name} (\\n  {fields_str}\\n);\"\n",
    "        #print(create_table_sql)\n",
    "    return create_table_sql\n",
    "\n",
    "def get_fieldmapping_by_api_endpoint(api_name,endpoint_name, data_extraction_path):\n",
    "    # Define the SQL query\n",
    "    query = f\"\"\" SELECT \n",
    "    dm.database_table,\n",
    "    fm.api_field_name,\n",
    "    fm.database_field_name,\n",
    "    fm.data_type_conversion,\n",
    "    fm.is_nullable,\n",
    "    der.extraction_path,\n",
    "    rs.sample_response\n",
    "FROM \n",
    "    apis a\n",
    "JOIN \n",
    "    endpoints e ON a.api_id = e.api_id\n",
    "JOIN \n",
    "    response_schemas rs ON e.endpoint_id = rs.endpoint_id\n",
    "JOIN \n",
    "    data_extraction_rules der ON rs.schema_id = der.schema_id\n",
    "JOIN \n",
    "    database_mappings dm ON der.extraction_id = dm.extraction_id\n",
    "JOIN \n",
    "    field_mappings fm ON dm.mapping_id = fm.mapping_id\n",
    "WHERE \n",
    "    a.api_name = '{api_name}' \n",
    "AND \n",
    "    e.endpoint_name = '{endpoint_name}'\n",
    "AND der.extraction_path = '{data_extraction_path}';\n",
    "    \"\"\"\n",
    "    # Execute the query and load the data into a Pandas DataFrame\n",
    "    with engine.connect() as connection:\n",
    "        df = pd.read_sql(query, connection)\n",
    "    return df\n",
    "\n",
    "# Function to execute the SQL query\n",
    "def execute_create_table(query):\n",
    "    try:\n",
    "        # Establish a connection to the database\n",
    "        connection = psycopg2.connect(DATABASE_URL)\n",
    "        \n",
    "        # Create a cursor object\n",
    "        cursor = connection.cursor()\n",
    "        \n",
    "        # Execute the CREATE TABLE SQL query\n",
    "        cursor.execute(query)\n",
    "        \n",
    "        # Commit the transaction\n",
    "        connection.commit()\n",
    "        \n",
    "        print(\"Table created successfully\")\n",
    "    \n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(f\"Error while executing SQL query: {error}\")\n",
    "    \n",
    "    finally:\n",
    "        # Close the cursor and connection\n",
    "        if connection:\n",
    "            cursor.close()\n",
    "            connection.close()\n",
    "\n",
    "create_table_sql = ''\n",
    "field_mapping_df = get_fieldmapping_by_api_endpoint('Sample API Test OCt22','Get Users','data')\n",
    "#print(field_mapping_df)\n",
    "if len(field_mapping_df) > 0:\n",
    "    create_table_sql = generate_create_table_from_fieldmapping_df(field_mapping_df)\n",
    "    execute_create_table(create_table_sql)\n",
    "    create_table_sql = create_table_sql.replace(\"IF NOT EXISTS\",\"\")\n",
    "# Display the DataFrame\n",
    "# print(df)\n",
    "print(create_table_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "76e2918a-3b64-4e47-98ac-4167addd5b11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_response = field_mapping_df['sample_response'].iloc[0]\n",
    "extraction_path = field_mapping_df['extraction_path'].iloc[0]\n",
    "extraction_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "de29566b-3a81-4b5d-b509-eaf3aa5fb65c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"page\":1,\"per_page\":6,\"total\":12,\"total_pages\":2,\"data\":[{\"id\":1,\"email\":\"george.bluth@reqres.in\",\"first_name\":\"George\",\"last_name\":\"Bluth\",\"avatar\":\"https://reqres.in/img/faces/1-image.jpg\"},{\"id\":2,\"email\":\"janet.weaver@reqres.in\",\"first_name\":\"Janet\",\"last_name\":\"Weaver\",\"avatar\":\"https://reqres.in/img/faces/2-image.jpg\"},{\"id\":3,\"email\":\"emma.wong@reqres.in\",\"first_name\":\"Emma\",\"last_name\":\"Wong\",\"avatar\":\"https://reqres.in/img/faces/3-image.jpg\"},{\"id\":4,\"email\":\"eve.holt@reqres.in\",\"first_name\":\"Eve\",\"last_name\":\"Holt\",\"avatar\":\"https://reqres.in/img/faces/4-image.jpg\"},{\"id\":5,\"email\":\"charles.morris@reqres.in\",\"first_name\":\"Charles\",\"last_name\":\"Morris\",\"avatar\":\"https://reqres.in/img/faces/5-image.jpg\"},{\"id\":6,\"email\":\"tracey.ramos@reqres.in\",\"first_name\":\"Tracey\",\"last_name\":\"Ramos\",\"avatar\":\"https://reqres.in/img/faces/6-image.jpg\"}],\"support\":{\"url\":\"https://reqres.in/#support-heading\",\"text\":\"To keep ReqRes free, contributions towards server costs are appreciated!\"}}'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "577836f7-8d44-409b-8340-792902631e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse\n",
    "\n",
    "def insert_data_into_dynamic_table(cursor, table_name, column_names, values):\n",
    "    placeholders = ', '.join(['%s'] * len(values))\n",
    "    columns = ', '.join(column_names)\n",
    "    query = f\"INSERT INTO {table_name} ({columns}) VALUES ({placeholders})\"\n",
    "    cursor.execute(query, values)\n",
    "\n",
    "def process_json_response_from_endpoint(sql_table, extraction_path, json_response):\n",
    "    # Parse the SQL table name and columns from the SQL string\n",
    "    table_name = sql_table.split()[2]\n",
    "    column_definitions = sql_table.split('(')[1].strip(');').split(',')\n",
    "    column_names = [col.split()[0] for col in column_definitions]\n",
    "    #print(column_names)\n",
    "    # Parse JSON response\n",
    "    data = json.loads(json_response)\n",
    "    # Get the data from the extraction path\n",
    "    data_list = data[extraction_path]\n",
    "    # Connect to PostgreSQL\n",
    "    conn = psycopg2.connect(DATABASE_URL)\n",
    "    cursor = conn.cursor()   \n",
    "    # Iterate over the JSON data and insert into the SQL table\n",
    "    for item in data_list:\n",
    "    #     # Extract the values for each column from the JSON response\n",
    "         values = [item.get(column) for column in column_names] \n",
    "         insert_data_into_dynamic_table(cursor, table_name, column_names, values)\n",
    "         \n",
    "    # # Commit the changes and query the table for demonstration\n",
    "    conn.commit()\n",
    "    # cursor.execute(f\"SELECT * FROM {table_name}\")\n",
    "    # rows = cursor.fetchall()\n",
    "    # # Close the connection\n",
    "    # conn.close()\n",
    "    #return rows\n",
    "# extraction_path = \"data\"\n",
    "# json_response = '{\"page\":1,\"per_page\":6,\"total\":12,\"total_pages\":2,\"data\":[{\"id\":1,\"email\":\"george.bluth@reqres.in\",\"first_name\":\"George\",\"last_name\":\"Bluth\",\"avatar\":\"https://reqres.in/img/faces/1-image.jpg\"},{\"id\":2,\"email\":\"janet.weaver@reqres.in\",\"first_name\":\"Janet\",\"last_name\":\"Weaver\",\"avatar\":\"https://reqres.in/img/faces/2-image.jpg\"},{\"id\":3,\"email\":\"emma.wong@reqres.in\",\"first_name\":\"Emma\",\"last_name\":\"Wong\",\"avatar\":\"https://reqres.in/img/faces/3-image.jpg\"},{\"id\":4,\"email\":\"eve.holt@reqres.in\",\"first_name\":\"Eve\",\"last_name\":\"Holt\",\"avatar\":\"https://reqres.in/img/faces/4-image.jpg\"},{\"id\":5,\"email\":\"charles.morris@reqres.in\",\"first_name\":\"Charles\",\"last_name\":\"Morris\",\"avatar\":\"https://reqres.in/img/faces/5-image.jpg\"},{\"id\":6,\"email\":\"tracey.ramos@reqres.in\",\"first_name\":\"Tracey\",\"last_name\":\"Ramos\",\"avatar\":\"https://reqres.in/img/faces/6-image.jpg\"}],\"support\":{\"url\":\"https://reqres.in/#support-heading\",\"text\":\"To keep ReqRes free, contributions towards server costs are appreciated!\"}}'\n",
    "json_response = field_mapping_df['sample_response'].iloc[0]\n",
    "extraction_path = field_mapping_df['extraction_path'].iloc[0]\n",
    "# Running the function\n",
    "process_json_response_from_endpoint(create_table_sql, extraction_path, json_response)\n",
    "# for row in rows:\n",
    "#     print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc585c5c-471f-46f3-baeb-5ce27f1d4b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "# !pip install sentence-transformers\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sqlalchemy import create_engine, text\n",
    "import os \n",
    "import time\n",
    "from pinecone import Pinecone, ServerlessSpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80dfc9f1-4a55-4d4f-98a7-f9d0b7098da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name=\"users_table\"\n",
    "PINECONE_API_KEY=\"pcsk_4vXc8e_8Jut8Xgywc9pGbjZKMzXFDdjMaMwmK7u1TX4Z4Mm4jCDwAV16RjDGtXNAaFCmQx\"\n",
    "index_name = f\"{table_name}-index\"\n",
    "index_name = index_name.replace(\"_\",\"-\")\n",
    "cloud = 'aws'\n",
    "region = 'us-east-1'\n",
    "spec = ServerlessSpec(cloud=cloud, region=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91d9fa2b-033d-488f-b184-e5e4ac2e7e0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "bc12781d-a568-4782-85ff-15ea135f4e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 1, 'first_name': 'George', 'last_name': 'Bluth', 'email': 'george.bluth@reqres.in'}\n",
      "{'id': 2, 'first_name': 'Janet', 'last_name': 'Weaver', 'email': 'janet.weaver@reqres.in'}\n",
      "{'id': 3, 'first_name': 'Emma', 'last_name': 'Wong', 'email': 'emma.wong@reqres.in'}\n",
      "{'id': 5, 'first_name': 'Charles', 'last_name': 'Morris', 'email': 'charles.morris@reqres.in'}\n",
      "{'id': 6, 'first_name': 'Tracey', 'last_name': 'Ramos', 'email': 'tracey.ramos@reqres.in'}\n",
      "{'id': 4, 'first_name': 'George', 'last_name': 'Holt', 'email': 'eve.holt@reqres.in'}\n"
     ]
    }
   ],
   "source": [
    "# Initialize Pinecone and sentence transformer\n",
    "# Connect to the database\n",
    "DATABASE_URL = \"postgresql://postgres.hzchwyuybezlqyiwgwki:vector_api_$#$@aws-0-us-west-1.pooler.supabase.com:6543/postgres\"\n",
    "\n",
    "engine = create_engine(DATABASE_URL)\n",
    "\n",
    "# Fetch all columns and user data dynamically\n",
    "def get_user_data(session,table_name):\n",
    "    query = text(f\"SELECT * FROM {table_name}\")\n",
    "    result = session.execute(query)\n",
    "    users_data = result.fetchall()\n",
    "    column_names = list(result.keys())\n",
    "    return users_data, column_names\n",
    "\n",
    "# Function to index data with all columns as metadata \n",
    "def index_user_data(users_data, column_names): \n",
    "    for user in users_data:\n",
    "    #     # Create metadata dictionary using column names and tuple indices\n",
    "         metadata = {column_names[i]: user[i] for i in range(len(column_names))}\n",
    "         print(metadata)  # Check the metadata being created\n",
    "        # Generate vector (using concatenated values for context)\n",
    "         user_vector = model.encode(\" \".join(str(user[i]) for i in range(len(column_names))))\n",
    "         #print(user_vector)\n",
    "        # Insert vector with metadata into Pinecone\n",
    "         index.upsert(vectors=[(str(metadata['id']), user_vector, metadata)])\n",
    "\n",
    "\n",
    "# Usage example: Fetch and index data\n",
    "with engine.connect() as session:\n",
    "    users_data, column_names = get_user_data(session,table_name)\n",
    "    index_user_data(users_data, column_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b3a9d1f6-849d-4c93-9e1c-83b9abad1f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = Pinecone(\n",
    "    api_key=PINECONE_API_KEY\n",
    ")\n",
    "existing_indexes = [\n",
    "    index_info[\"name\"] for index_info in pc.list_indexes()\n",
    "]\n",
    "# check if index already exists (it shouldn't if this is first time)\n",
    "if index_name not in existing_indexes:\n",
    "    # if does not exist, create index\n",
    "    pc.create_index(\n",
    "        index_name,\n",
    "        dimension=384,  # dimensionality of minilm\n",
    "        metric='cosine',\n",
    "        spec=spec\n",
    "    )\n",
    "    # wait for index to be initialized\n",
    "    while not pc.describe_index(index_name).status['ready']:\n",
    "        time.sleep(1)\n",
    "\n",
    "# connect to index\n",
    "index = pc.Index(index_name)\n",
    "time.sleep(1)\n",
    "# view index stats\n",
    "index.describe_index_stats()\n",
    "# pinecone.init(api_key=PINECONE_API_KEY)\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "23e71cb0-2955-4cdf-84de-8f6e027d616e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results without filter: [{'ID': '1', 'Metadata': {'email': 'george.bluth@reqres.in', 'first_name': 'George shankar', 'id': 1.0, 'last_name': 'Bluth'}, 'Score': 0.330017865}, {'ID': '5', 'Metadata': {'email': 'charles.morris@reqres.in', 'first_name': 'Charles', 'id': 5.0, 'last_name': 'Morris'}, 'Score': 0.286311507}, {'ID': '3', 'Metadata': {'email': 'emma.wong@reqres.in', 'first_name': 'Emma', 'id': 3.0, 'last_name': 'Wong'}, 'Score': 0.188862056}, {'ID': '4', 'Metadata': {'email': 'eve.holt@reqres.in', 'first_name': 'Eve', 'id': 4.0, 'last_name': 'Holt'}, 'Score': 0.178303391}, {'ID': '6', 'Metadata': {'email': 'tracey.ramos@reqres.in', 'first_name': 'Tracey', 'id': 6.0, 'last_name': 'Ramos'}, 'Score': 0.14218843}]\n"
     ]
    }
   ],
   "source": [
    "def search_with_optional_filter(first_name_query, filter_attribute=None, filter_value=None):\n",
    "    # Generate vector for the first name query\n",
    "    query_vector = model.encode(first_name_query).tolist()  # Convert ndarray to list\n",
    "\n",
    "    # Prepare the search parameters\n",
    "    search_params = {\n",
    "        \"vector\": query_vector,\n",
    "        \"top_k\": 5,  # Number of nearest neighbors to return\n",
    "        \"include_metadata\": True  # Include metadata in the results\n",
    "    }\n",
    "    # Apply filter if provided\n",
    "    if filter_attribute and filter_value:\n",
    "        search_params[\"filter\"] = {filter_attribute: filter_value}  # Apply the specified filter\n",
    "\n",
    "    # Execute the query\n",
    "    query_response = index.query(**search_params)\n",
    "\n",
    "    # Process and print the results\n",
    "    results = []\n",
    "    for match in query_response['matches']:\n",
    "        # Append the ID, metadata, and score to the results\n",
    "        results.append({\n",
    "            \"ID\": match['id'],\n",
    "            \"Metadata\": match['metadata'],\n",
    "            \"Score\": match['score']  # Confidence score\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example usage without filtering\n",
    "results_no_filter = search_with_optional_filter(\"george\")\n",
    "print(\"Results without filter:\", results_no_filter)\n",
    "# Example usage with filtering\n",
    "#results_with_filter = search_with_optional_filter(\"George\", \"last_name\", \"Holt\")\n",
    "#print(\"Results with filter:\", results_with_filter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "45c1145c-8a35-4493-b4cf-6bfaf97b3637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inserted successfully.\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "\n",
    " \n",
    "# Function to insert data into meta_data_vector_db\n",
    "def insert_meta_data_vector(index_name, table_name, metadata_fields, vector_fields, db_url):\n",
    "    try:\n",
    "        # Connect to the database using the connection URL\n",
    "        with psycopg2.connect(db_url) as conn:\n",
    "            with conn.cursor() as cursor:\n",
    "                # Define the SQL query\n",
    "                query = \"\"\"\n",
    "                INSERT INTO meta_data_vector_db (index_name, table_name, metadata_fields, vector_fields)\n",
    "                VALUES (%s, %s, %s, %s)\n",
    "                \"\"\"\n",
    "                # Execute the query with the provided data\n",
    "                cursor.execute(query, (index_name, table_name, metadata_fields, vector_fields))\n",
    "                conn.commit()\n",
    "        print(\"Data inserted successfully.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error inserting data: {e}\")\n",
    "\n",
    "# Sample data to insert\n",
    "index_name = 'example_index'\n",
    "table_name = 'users_table'\n",
    "metadata_fields = 'first_name, last_name, email'\n",
    "vector_fields = 'full_name_vector'\n",
    "\n",
    "# Call the function with the connection URL\n",
    "insert_meta_data_vector(index_name, table_name, metadata_fields, vector_fields, DATABASE_URL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "2cf82e29-d9f8-4c26-bb65-5df272220258",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Sample JSON data\n",
    "json_data = {\n",
    "    \"page\": 1,\n",
    "    \"per_page\": 6,\n",
    "    \"total\": 12,\n",
    "    \"total_pages\": 2,\n",
    "    \"data\": {\n",
    "        \"users\": [\n",
    "            {\n",
    "                \"id\": 1,\n",
    "                \"email\": \"george.bluth@reqres.in\",\n",
    "                \"first_name\": \"George\",\n",
    "                \"last_name\": \"Bluth\",\n",
    "                \"avatar\": \"https://reqres.in/img/faces/1-image.jpg\"\n",
    "            },\n",
    "            {\n",
    "                \"id\": 2,\n",
    "                \"email\": \"janet.weaver@reqres.in\",\n",
    "                \"first_name\": \"Janet\",\n",
    "                \"last_name\": \"Weaver\",\n",
    "                \"avatar\": \"https://reqres.in/img/faces/2-image.jpg\"\n",
    "            },\n",
    "            {\n",
    "                \"id\": 3,\n",
    "                \"email\": \"emma.wong@reqres.in\",\n",
    "                \"first_name\": \"Emma\",\n",
    "                \"last_name\": \"Wong\",\n",
    "                \"avatar\": \"https://reqres.in/img/faces/3-image.jpg\"\n",
    "            },\n",
    "            {\n",
    "                \"id\": 4,\n",
    "                \"email\": \"eve.holt@reqres.in\",\n",
    "                \"first_name\": \"Eve\",\n",
    "                \"last_name\": \"Holt\",\n",
    "                \"avatar\": \"https://reqres.in/img/faces/4-image.jpg\"\n",
    "            },\n",
    "            {\n",
    "                \"id\": 5,\n",
    "                \"email\": \"charles.morris@reqres.in\",\n",
    "                \"first_name\": \"Charles\",\n",
    "                \"last_name\": \"Morris\",\n",
    "                \"avatar\": \"https://reqres.in/img/faces/5-image.jpg\"\n",
    "            },\n",
    "            {\n",
    "                \"id\": 6,\n",
    "                \"email\": \"tracey.ramos@reqres.in\",\n",
    "                \"first_name\": \"Tracey\",\n",
    "                \"last_name\": \"Ramos\",\n",
    "                \"avatar\": \"https://reqres.in/img/faces/6-image.jpg\"\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    \"support\": {\n",
    "        \"url\": \"https://reqres.in/#support-heading\",\n",
    "        \"text\": \"To keep ReqRes free, contributions towards server costs are appreciated!\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Define the path as a string\n",
    "path = \"data/users\"\n",
    "\n",
    "# Split the path into keys and navigate through json_data\n",
    "def get_value_by_path(data, path):\n",
    "    keys = path.split(\"/\")\n",
    "    for key in keys:\n",
    "        data = data.get(key, {})\n",
    "    return data\n",
    "\n",
    "# Extract data at the specified path\n",
    "result = get_value_by_path(json_data, path)\n",
    "\n",
    "# Print the result\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "a4ceb20e-dd00-4900-bc5d-3b95aa9c31c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'users': [{'id': 1,\n",
       "   'email': 'george.bluth@reqres.in',\n",
       "   'first_name': 'George',\n",
       "   'last_name': 'Bluth',\n",
       "   'avatar': 'https://reqres.in/img/faces/1-image.jpg'},\n",
       "  {'id': 2,\n",
       "   'email': 'janet.weaver@reqres.in',\n",
       "   'first_name': 'Janet',\n",
       "   'last_name': 'Weaver',\n",
       "   'avatar': 'https://reqres.in/img/faces/2-image.jpg'},\n",
       "  {'id': 3,\n",
       "   'email': 'emma.wong@reqres.in',\n",
       "   'first_name': 'Emma',\n",
       "   'last_name': 'Wong',\n",
       "   'avatar': 'https://reqres.in/img/faces/3-image.jpg'},\n",
       "  {'id': 4,\n",
       "   'email': 'eve.holt@reqres.in',\n",
       "   'first_name': 'Eve',\n",
       "   'last_name': 'Holt',\n",
       "   'avatar': 'https://reqres.in/img/faces/4-image.jpg'},\n",
       "  {'id': 5,\n",
       "   'email': 'charles.morris@reqres.in',\n",
       "   'first_name': 'Charles',\n",
       "   'last_name': 'Morris',\n",
       "   'avatar': 'https://reqres.in/img/faces/5-image.jpg'},\n",
       "  {'id': 6,\n",
       "   'email': 'tracey.ramos@reqres.in',\n",
       "   'first_name': 'Tracey',\n",
       "   'last_name': 'Ramos',\n",
       "   'avatar': 'https://reqres.in/img/faces/6-image.jpg'}]}"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "b402c9dd-30ba-43fa-ab93-e4c9f85de0a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 1, 'email': 'george.bluth@reqres.in', 'first_name': 'George', 'last_name': 'Bluth', 'avatar': 'https://reqres.in/img/faces/1-image.jpg'}, {'id': 2, 'email': 'janet.weaver@reqres.in', 'first_name': 'Janet', 'last_name': 'Weaver', 'avatar': 'https://reqres.in/img/faces/2-image.jpg'}, {'id': 3, 'email': 'emma.wong@reqres.in', 'first_name': 'Emma', 'last_name': 'Wong', 'avatar': 'https://reqres.in/img/faces/3-image.jpg'}, {'id': 4, 'email': 'eve.holt@reqres.in', 'first_name': 'Eve', 'last_name': 'Holt', 'avatar': 'https://reqres.in/img/faces/4-image.jpg'}, {'id': 5, 'email': 'charles.morris@reqres.in', 'first_name': 'Charles', 'last_name': 'Morris', 'avatar': 'https://reqres.in/img/faces/5-image.jpg'}, {'id': 6, 'email': 'tracey.ramos@reqres.in', 'first_name': 'Tracey', 'last_name': 'Ramos', 'avatar': 'https://reqres.in/img/faces/6-image.jpg'}]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# JSON data as a string\n",
    "json_string = '''{\n",
    "    \"page\": 1,\n",
    "    \"per_page\": 6,\n",
    "    \"total\": 12,\n",
    "    \"total_pages\": 2,\n",
    "    \"data\": {\n",
    "        \"users\": [\n",
    "            {\n",
    "                \"id\": 1,\n",
    "                \"email\": \"george.bluth@reqres.in\",\n",
    "                \"first_name\": \"George\",\n",
    "                \"last_name\": \"Bluth\",\n",
    "                \"avatar\": \"https://reqres.in/img/faces/1-image.jpg\"\n",
    "            },\n",
    "            {\n",
    "                \"id\": 2,\n",
    "                \"email\": \"janet.weaver@reqres.in\",\n",
    "                \"first_name\": \"Janet\",\n",
    "                \"last_name\": \"Weaver\",\n",
    "                \"avatar\": \"https://reqres.in/img/faces/2-image.jpg\"\n",
    "            },\n",
    "            {\n",
    "                \"id\": 3,\n",
    "                \"email\": \"emma.wong@reqres.in\",\n",
    "                \"first_name\": \"Emma\",\n",
    "                \"last_name\": \"Wong\",\n",
    "                \"avatar\": \"https://reqres.in/img/faces/3-image.jpg\"\n",
    "            },\n",
    "            {\n",
    "                \"id\": 4,\n",
    "                \"email\": \"eve.holt@reqres.in\",\n",
    "                \"first_name\": \"Eve\",\n",
    "                \"last_name\": \"Holt\",\n",
    "                \"avatar\": \"https://reqres.in/img/faces/4-image.jpg\"\n",
    "            },\n",
    "            {\n",
    "                \"id\": 5,\n",
    "                \"email\": \"charles.morris@reqres.in\",\n",
    "                \"first_name\": \"Charles\",\n",
    "                \"last_name\": \"Morris\",\n",
    "                \"avatar\": \"https://reqres.in/img/faces/5-image.jpg\"\n",
    "            },\n",
    "            {\n",
    "                \"id\": 6,\n",
    "                \"email\": \"tracey.ramos@reqres.in\",\n",
    "                \"first_name\": \"Tracey\",\n",
    "                \"last_name\": \"Ramos\",\n",
    "                \"avatar\": \"https://reqres.in/img/faces/6-image.jpg\"\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    \"support\": {\n",
    "        \"url\": \"https://reqres.in/#support-heading\",\n",
    "        \"text\": \"To keep ReqRes free, contributions towards server costs are appreciated!\"\n",
    "    }\n",
    "}'''\n",
    "\n",
    "# Parse the JSON string into a Python dictionary\n",
    "json_data = json.loads(json_string)\n",
    "\n",
    "# Define the path as a string\n",
    "path = \"data/users\"\n",
    "\n",
    "# Function to navigate JSON using the given path\n",
    "def get_value_by_path(data, path):\n",
    "    keys = path.split(\"/\")\n",
    "    for key in keys:\n",
    "        data = data.get(key, {})\n",
    "    return data\n",
    "\n",
    "# Extract data at the specified path\n",
    "result = get_value_by_path(json_data, path)\n",
    "\n",
    "# Print the result\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "de474abb-6801-4eb4-9ebd-bc11a999a85d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 1, 'email': 'george.bluth@reqres.in', 'first_name': 'George', 'last_name': 'Bluth', 'avatar': 'https://reqres.in/img/faces/1-image.jpg'}, {'id': 2, 'email': 'janet.weaver@reqres.in', 'first_name': 'Janet', 'last_name': 'Weaver', 'avatar': 'https://reqres.in/img/faces/2-image.jpg'}, {'id': 3, 'email': 'emma.wong@reqres.in', 'first_name': 'Emma', 'last_name': 'Wong', 'avatar': 'https://reqres.in/img/faces/3-image.jpg'}, {'id': 4, 'email': 'eve.holt@reqres.in', 'first_name': 'Eve', 'last_name': 'Holt', 'avatar': 'https://reqres.in/img/faces/4-image.jpg'}, {'id': 5, 'email': 'charles.morris@reqres.in', 'first_name': 'Charles', 'last_name': 'Morris', 'avatar': 'https://reqres.in/img/faces/5-image.jpg'}, {'id': 6, 'email': 'tracey.ramos@reqres.in', 'first_name': 'Tracey', 'last_name': 'Ramos', 'avatar': 'https://reqres.in/img/faces/6-image.jpg'}]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# JSON data as a string\n",
    "json_string = '''\n",
    "{\"page\": 1, \"per_page\": 6, \"total\": 12, \"total_pages\": 2, \"data\": [{\"id\": 1, \"email\": \"george.bluth@reqres.in\", \"first_name\": \"George\", \"last_name\": \"Bluth\", \"avatar\": \"https://reqres.in/img/faces/1-image.jpg\"}, {\"id\": 2, \"email\": \"janet.weaver@reqres.in\", \"first_name\": \"Janet\", \"last_name\": \"Weaver\", \"avatar\": \"https://reqres.in/img/faces/2-image.jpg\"}, {\"id\": 3, \"email\": \"emma.wong@reqres.in\", \"first_name\": \"Emma\", \"last_name\": \"Wong\", \"avatar\": \"https://reqres.in/img/faces/3-image.jpg\"}, {\"id\": 4, \"email\": \"eve.holt@reqres.in\", \"first_name\": \"Eve\", \"last_name\": \"Holt\", \"avatar\": \"https://reqres.in/img/faces/4-image.jpg\"}, {\"id\": 5, \"email\": \"charles.morris@reqres.in\", \"first_name\": \"Charles\", \"last_name\": \"Morris\", \"avatar\": \"https://reqres.in/img/faces/5-image.jpg\"}, {\"id\": 6, \"email\": \"tracey.ramos@reqres.in\", \"first_name\": \"Tracey\", \"last_name\": \"Ramos\", \"avatar\": \"https://reqres.in/img/faces/6-image.jpg\"}], \"support\": {\"url\": \"https://reqres.in/#support-heading\", \"text\": \"To keep ReqRes free, contributions towards server costs are appreciated!\"}}\n",
    "\n",
    "'''\n",
    "\n",
    "# Parse the JSON string into a Python dictionary\n",
    "json_data = json.loads(json_string)\n",
    "\n",
    "# Define the path as a string\n",
    "path = \"data\"\n",
    "\n",
    "# Function to navigate JSON using the given path\n",
    "def get_value_by_path(data, path):\n",
    "    keys = path.split(\"/\")\n",
    "    for key in keys:\n",
    "        data = data.get(key, {})\n",
    "    return data\n",
    "\n",
    "# Extract data at the specified path\n",
    "result = get_value_by_path(json_data, path)\n",
    "\n",
    "# Print the result\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cfdf3f6f-64b1-423e-a7e5-8e376483e9c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key\n",
      "X-Api-Key\n"
     ]
    }
   ],
   "source": [
    "headers_array = [\n",
    "    {\"key\": \"X-Api-Key\"}\n",
    "    # Add more headers if needed, each as a dictionary\n",
    "]\n",
    "for header in headers_array:\n",
    "    for kv in header:\n",
    "      print(kv)\n",
    "      print(header[kv])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c40d3b26-616b-4ca2-b4b4-ce4279ad953a",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers_array = [\n",
    "    {\"key\": \"X-Api-Key\", \"value\": \"ga3PeN7t.JRqpg79DHmw5xu9lfC4alAqcLyBofmtj\", \"enabled\": True},\n",
    "    # Add more headers if needed, each as a dictionary\n",
    "]\n",
    "\n",
    "# Prepare headers dictionary for the request\n",
    "headers = {header['key']: header['value'] for header in headers_array if header.get(\"enabled\", True)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fe4fcc42-86d1-4230-9c8c-9e1c10a1763d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X-Api-Key': 'ga3PeN7t.JRqpg79DHmw5xu9lfC4alAqcLyBofmtj'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "600e3784-b178-4bb4-8cd2-756b22e8375a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "def translate_text(text, source_language=\"English\", target_language=\"French\"):\n",
    "    \"\"\"\n",
    "    Translate text from source_language to target_language using a pre-trained T5 model.\n",
    "\n",
    "    Args:\n",
    "        text (str): Text to be translated.\n",
    "        source_language (str): Source language of the text.\n",
    "        target_language (str): Target language for translation.\n",
    "\n",
    "    Returns:\n",
    "        str: Translated text.\n",
    "    \"\"\"\n",
    "    # Load pre-trained T5 model and tokenizer\n",
    "    model_name = \"t5-small\"  # You can also use \"t5-base\" or \"t5-large\" for better performance\n",
    "    tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "    model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "    # Format the input text for translation\n",
    "    task_prefix = f\"translate {source_language} to {target_language}: \"\n",
    "    input_text = task_prefix + text\n",
    "\n",
    "    # Tokenize the input text\n",
    "    inputs = tokenizer.encode(input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "\n",
    "    # Generate translation\n",
    "    outputs = model.generate(inputs, max_length=512, num_beams=4, early_stopping=True)\n",
    "\n",
    "    # Decode the output tokens to text\n",
    "    translated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    return translated_text\n",
    "\n",
    "# Example usage\n",
    "#if __name__ == \"__main__\":\n",
    "source_text = \"que se passe-t-il dans le monde entre deux pays\"\n",
    "source_lang = \"French\"\n",
    "target_lang = \"English\"\n",
    "\n",
    "translated_text = translate_text(source_text, source_language=source_lang, target_language=target_lang)\n",
    "# print(f\"Original text: {source_text}\")\n",
    "# print(f\"Translated text: {translated_text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef200225-916b-4c7b-a1f5-4e65be010243",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
